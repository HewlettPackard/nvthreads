@CODE Version: 1.18 Graph Inference Engine
=================================================================================================

@Last Version: In-memory graph, numa-aware, optimized to local reads and batched remote writes. 
Last update: May 29, 2015.

@Quick Summary:
This version implements Gibbs Sampling Inference method with the following design considerations:

	a.It implements NUMA-aware design, including different functions to access the graph topology in order to maximize scalability 
	and performance.

	b.It builds a graph topology structure which is an in-memory data structure that stores vertices, factors and neighbors of vertices 
	aligned in a way to minimize cache misses and make data access efficient (R/W remote/local). 

	c. The graph topology is partitioned over the numa sockets using numa_allocator. Global states are replicated over the sockets
	in order to ensure local reads for neighbors values. Then, this implies remote writes which are batched together to make 
	memory copies efficient. 

	d.  There are workers assigned to each socket partition. Each worker is assigned to a specific core within the socket. Each worker is responsible 
	for processing specific vertices of graph for N iterations.


@Software package dependencies:
a.boost libraries
	use: sudo yum install boost-devel
b.numalib
	use: sudo yum install numactl-devel
c.pthreads
	 
@PACKAGE:

	code/ source code
	data/ graph example and configuration example
	demo/ script to run the demo



@How to compile it
Go to code/ folder
then enter make

@How to run it
Enter:
	./gibbsApp <configurationFile> <input graph file, alchemy format with factors> <-refresh=100>

or go to demo/ folder and run the demo script.


Example:
./gibbsDSNApp configuration-10T.txt graph_D12V20M120E.alchemy.factors -refresh=1000

This example runs the graph inference on graph_D12V20M120E (graph) using the configuration specified in configuration-10T.txt file 
and will execute remote update every 1000.


@Parameter Description:
1. ConfigurationFile: includes the main configuration for the data placement and inference process as follows:

	Example: 
	filename: configuration-80T.txt
	
	#Threads,#samples,outputFilename,numasocketsTouse(1;2),#SamplesSnapshop,threshold
	80,100,out1,8,10,0.03


	a. This configuration file will configure the engine with:  
		80 threads, 100 iterations, out1 is the output file, uses 8 sockets, convergence test every 10 iterations,
		and convergence threshold of 0.03.
	b. The configuration file is included in the code folder.
	c. The file can be changed to configure different experiments.

2. Input graph includes: 

	a.  Alchemy file format to read graph and factors.	
		-filename nomenclature:  graph_D12V20M120E.alchemy.factors 
		-Description:        	  D= Degree, V=number of vertices, E=number of edges
							     The graph is a regular graph.  All vertices have Degree=12, 20M Vertices, and 120 Million edges.

	b. Graph partition file to read partition sizes for each socket.
		The system assumes that the partitions file exists in the same path of the graph input file with a postfix ".par".					
		For example:
		-filename:  graph_D12V2M1200E.alchemy.factors.par
		
		Notes:		
		-The number of partitions should be equal to the number of numa nodes defined on the configuration file. 
		For instance, for 8 sockets, the file should contain 8 lines with the number of vertices on each partition. 
		-The sum of the number of vertices across all the partitions should equal the total number of vertices in the graph.
		
3. -refresh:
		Optional parameter to determine the number of updates that will batched to remote replicas. Default value is 100.
			

@Output:
	Generates 3 different files:
	+ .tsv    contains the statistics of how many times the vertex state has been zero (this gives the marginal distribution of each vertex)
	+ .timer  includes time and memory statistics.
	+ .conv   includes convergence statistics.


@COMMENTS:
-Using the configuration file, graph of 120M edges is loaded in 280 seconds and 100 iterations of inference takes 14 sec (DL980 mahine) 

Authors
@Fei, Tere, Nandish, Krishna,Hideaki
